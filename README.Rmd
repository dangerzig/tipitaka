---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# tipitaka

<!-- badges: start -->
<!-- badges: end -->

The goal of tipitaka is to allow students and researchers to apply the tools of computational linguistics to the ancient Buddhist texts known as the Tipitaka or Pali Canon.

The Tipitaka is the canonical scripture of Theravadin Buddhists worldwide. It purports to record the direct teachings of the historical Buddha. It was first recorded in written form in what is now Sri Lanka, likely around 100 BCE.

The tipitaka package provides the texts of the Tipitaka in various electronic forms, plus functions for working with the Pali language.

## What's New in Version 1.0

Version 1.0 adds a **critical edition** of the Sutta Pitaka with two major improvements:

* **Lemmatization**: Words are grouped by dictionary headword using the [Digital Pali Dictionary](https://digitalpalidictionary.github.io/). For example, "buddhassa", "buddho", and "buddhaṃ" are all counted under "buddha". This enables much more meaningful text analysis.

* **Sutta-level granularity**: Word frequencies are available for each individual sutta (~5,700 suttas), not just by volume. This allows fine-grained comparison of texts.

The critical edition is based on the Pali Text Society edition with ~500 corrections identified by comparing the SuttaCentral and VRI witnesses.

## Data Sources

The package includes two data sources:

**VRI Edition** (original datasets): The complete Tipitaka from the Chattha Sangāyana Tipiṭaka version 4.0 (CST4) published by the Vipassana Research Institute. This covers all three pitakas (Vinaya, Sutta, and Abhidhamma).

* `tipitaka_raw`, `tipitaka_long`, `tipitaka_wide` - Full canon, volume-level

**Critical Edition** (new in v1.0): A lemmatized critical edition of the Sutta Pitaka only.

* `tipitaka_long_critical`, `tipitaka_wide_critical` - Lemma frequencies by nikaya
* `tipitaka_suttas_long`, `tipitaka_suttas_wide` - Lemma frequencies by sutta
* `tipitaka_long_words` - Surface forms (non-lemmatized) for comparison

## Pali Alphabet

There is no universal script for Pali; traditionally each Buddhist country uses its own script to write Pali phonetically. This package uses the Roman script and the diacritical system developed by the PTS. However, note that the Pali alphabet does NOT follow the alphabetical ordering of English or other Roman-script languages. For this reason, tipitaka includes `pali_alphabet` giving the full Pali alphabet in order, and the functions `pali_lt`, `pali_gt`, `pali_eq`, and `pali_sort` for comparing and sorting Pali strings.

## Installation

You can install the released version of tipitaka from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("tipitaka")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("dangerzig/tipitaka")
```
## Example

You can use tipitaka to do clustering analysis of the various books of the Pali Canon. For example:

```{r dendogram, message = FALSE, warning = FALSE}
library(tipitaka)
dist_m <- dist(tipitaka_wide)
cluster <- hclust(dist_m)
plot(cluster)
```

You can also create traditional k-means clusters and visualize these using packages like `factoextra`:

```{r kmeans, message = FALSE, warning = FALSE}
library(factoextra) # great visualizer for clusters
km <- kmeans(dist_m, 2, nstart = 25, algorithm = "Lloyd")
fviz_cluster(km, dist_m, labelsize = 12, repel = TRUE)
```

You can also explore the topics of various parts of the Tipitaka using packges like `wordcloud`:

```{r wordclouds, message = FALSE, warning = FALSE}
library(wordcloud)
library(dplyr)
sati_sutta_long %>%
  anti_join(pali_stop_words, by = "word") %>%
  with(wordcloud(word, n, max.words = 40)) 
```

Finally, we can look at word frequency by rank:
```{r freq-by-word, message = FALSE, warning = FALSE}
library(dplyr, quietly = TRUE)
freq_by_rank <- tipitaka_long %>%
  group_by(word) %>%
  add_count(wt = n, name = "word_total") %>%
  ungroup() %>%
  distinct(word, .keep_all = TRUE) %>%
  mutate(tipitaka_total =
           sum(distinct(tipitaka_long, book,
                        .keep_all = TRUE)$total)) %>%
    transform(freq = word_total/tipitaka_total) %>%
  arrange(desc(freq)) %>%
  mutate(rank = row_number()) %>%
  select(-n, -total, -book)

freq_by_rank %>%
  ggplot(aes(rank, freq)) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
  scale_x_log10() +
  scale_y_log10()
```

## Lemmatized Analysis (New in v1.0)

The lemmatized critical edition enables more meaningful clustering by grouping inflected forms:

```{r dendogram-critical, message = FALSE, warning = FALSE}
# Cluster the five nikayas using lemmatized data
dist_critical <- dist(tipitaka_wide_critical)
hc_critical <- hclust(dist_critical)
plot(hc_critical, main = "Nikaya Clustering (Lemmatized)")
```

You can search for specific lemmas across all suttas:

```{r search-lemma, message = FALSE, warning = FALSE}
# Find suttas that mention "nibbana" most frequently
nibbana <- search_lemma("nibbana")
head(nibbana[, c("sutta", "nikaya", "n", "freq")], 10)
```

